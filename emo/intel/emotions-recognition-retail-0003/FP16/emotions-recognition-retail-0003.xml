<?xml version="1.0"?>
<net name="0003_EmoNet_ResNet10" version="11">
	<layers>
		<layer id="0" name="data" type="Parameter" version="opset1">
			<data shape="1,3,64,64" element_type="f32" />
			<rt_info>
				<attribute name="old_api_map_element_type" version="0" value="f16" />
				<attribute name="preprocessing" version="0" />
			</rt_info>
			<output>
				<port id="0" precision="FP32" names="data">
					<dim>1</dim>
					<dim>3</dim>
					<dim>64</dim>
					<dim>64</dim>
					<rt_info>
						<attribute name="layout" version="0" layout="[N,C,H,W]" />
					</rt_info>
				</port>
			</output>
		</layer>
		<layer id="1" name="data_mul_2312_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 3, 1, 1" offset="0" size="6" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2" name="data_mul_2312" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3" name="BatchNorm1/mean/Fused_Mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>64</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>64</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="4" name="data_add_2314_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 3, 1, 1" offset="6" size="6" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="5" name="data_add_2314" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="6" name="BatchNorm1/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>64</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="data">
					<dim>1</dim>
					<dim>3</dim>
					<dim>64</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="7" name="BatchNorm2/mean/Fused_Mul__copy_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="64, 3, 7, 7" offset="12" size="18816" />
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</output>
		</layer>
		<layer id="8" name="BatchNorm2/mean/Fused_Mul__copy" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</output>
		</layer>
		<layer id="9" name="Convolution1/WithoutBiases" type="Convolution" version="opset1">
			<data strides="2, 2" dilations="1, 1" pads_begin="3, 3" pads_end="3, 3" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>64</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>32</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="10" name="data_add_23172322_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 64, 1, 1" offset="18828" size="128" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="11" name="data_add_23172322" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="12" name="Convolution1/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>32</dim>
					<dim>32</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>32</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="13" name="ReLU1" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>32</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Convolution1,Dropout_ReLU1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>32</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="14" name="Pooling1" type="MaxPool" version="opset8">
			<data strides="2, 2" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" kernel="3, 3" rounding_type="ceil" auto_pad="explicit" index_element_type="i64" axis="0" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>32</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Pooling1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="15" name="BatchNorm3/mean/Fused_Mul__copy_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="64, 64, 3, 3" offset="18956" size="73728" />
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="16" name="BatchNorm3/mean/Fused_Mul__copy" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="17" name="Convolution2" type="Convolution" version="opset1">
			<data strides="1, 1" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="18" name="data_add_23252330_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 64, 1, 1" offset="92684" size="128" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="19" name="data_add_23252330" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="20" name="BatchNorm3/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="21" name="ReLU2" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Convolution2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="22" name="96_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="64, 64, 3, 3" offset="92812" size="73728" />
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="23" name="96" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="24" name="Convolution3" type="Convolution" version="opset1">
			<data strides="1, 1" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="25" name="Eltwise1" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="26" name="data_mul_23322336_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 64, 1, 1" offset="166540" size="128" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="27" name="data_mul_23322336" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="28" name="BatchNorm4/mean/Fused_Mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="29" name="data_add_23332338_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 64, 1, 1" offset="166668" size="128" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="30" name="data_add_23332338" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="31" name="BatchNorm4/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="32" name="ReLU3" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Dropout_ReLU3,Eltwise1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="33" name="BatchNorm5/mean/Fused_Mul__copy_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="128, 64, 3, 3" offset="166796" size="147456" />
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="34" name="BatchNorm5/mean/Fused_Mul__copy" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>128</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="35" name="Convolution4" type="Convolution" version="opset1">
			<data strides="2, 2" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>128</dim>
					<dim>64</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="36" name="data_add_23412346_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 128, 1, 1" offset="314252" size="256" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="37" name="data_add_23412346" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="38" name="BatchNorm5/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="39" name="ReLU4" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Convolution4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="40" name="105_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="128, 128, 3, 3" offset="314508" size="294912" />
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="41" name="105" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>128</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="42" name="Convolution5" type="Convolution" version="opset1">
			<data strides="1, 1" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>128</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution5">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="43" name="115_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="128, 64, 1, 1" offset="609420" size="16384" />
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="44" name="115" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>128</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="45" name="Convolution6" type="Convolution" version="opset1">
			<data strides="2, 2" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>16</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>128</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution6">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="46" name="Eltwise2" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="47" name="data_mul_23482352_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 128, 1, 1" offset="625804" size="256" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="48" name="data_mul_23482352" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="49" name="BatchNorm6/mean/Fused_Mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="50" name="data_add_23492354_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 128, 1, 1" offset="626060" size="256" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="51" name="data_add_23492354" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="52" name="BatchNorm6/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="53" name="ReLU5" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Dropout_ReLU5,Eltwise2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="54" name="BatchNorm7/mean/Fused_Mul__copy_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="256, 128, 3, 3" offset="626316" size="589824" />
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="55" name="BatchNorm7/mean/Fused_Mul__copy" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="56" name="Convolution7" type="Convolution" version="opset1">
			<data strides="2, 2" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>128</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="57" name="data_add_23572362_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 256, 1, 1" offset="1216140" size="512" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="58" name="data_add_23572362" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="59" name="BatchNorm7/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution7">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="60" name="ReLU6" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Convolution7">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="61" name="111_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="256, 256, 3, 3" offset="1216652" size="1179648" />
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="62" name="111" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="63" name="Convolution8" type="Convolution" version="opset1">
			<data strides="1, 1" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution8">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="64" name="106_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="256, 128, 1, 1" offset="2396300" size="65536" />
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="65" name="106" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="66" name="Convolution9" type="Convolution" version="opset1">
			<data strides="2, 2" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>128</dim>
					<dim>8</dim>
					<dim>8</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution9">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="67" name="Eltwise3" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise3">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="68" name="data_mul_23642368_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 256, 1, 1" offset="2461836" size="512" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="69" name="data_mul_23642368" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="70" name="BatchNorm8/mean/Fused_Mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="71" name="data_add_23652370_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 256, 1, 1" offset="2462348" size="512" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="72" name="data_add_23652370" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="73" name="BatchNorm8/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise3">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="74" name="ReLU7" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Dropout_ReLU7,Eltwise3">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="75" name="BatchNorm9/mean/Fused_Mul__copy_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="256, 256, 3, 3" offset="2462860" size="1179648" />
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="76" name="BatchNorm9/mean/Fused_Mul__copy" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="77" name="Convolution10" type="Convolution" version="opset1">
			<data strides="2, 2" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="78" name="data_add_23732378_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 256, 1, 1" offset="3642508" size="512" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="79" name="data_add_23732378" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="80" name="BatchNorm9/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution10">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="81" name="ReLU8" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Convolution10">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="82" name="104_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="256, 256, 3, 3" offset="3643020" size="1179648" />
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="83" name="104" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="84" name="Convolution11" type="Convolution" version="opset1">
			<data strides="1, 1" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution11">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="85" name="114_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="256, 256, 1, 1" offset="4822668" size="131072" />
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="86" name="114" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="87" name="Convolution12" type="Convolution" version="opset1">
			<data strides="2, 2" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>4</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Convolution12">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="88" name="Eltwise4" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise4">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="89" name="data_mul_23802384_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 256, 1, 1" offset="4953740" size="512" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="90" name="data_mul_23802384" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="91" name="BatchNorm10/mean/Fused_Mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="92" name="data_add_23812386_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 256, 1, 1" offset="4954252" size="512" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="93" name="data_add_23812386" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="94" name="BatchNorm10/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="Eltwise4">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="95" name="ReLU9" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="Dropout_ReLU9,Eltwise4">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="96" name="78_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="5, 256, 2, 2" offset="4954764" size="10240" />
			<output>
				<port id="0" precision="FP16">
					<dim>5</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="97" name="78" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>5</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>5</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="98" name="emotion5_conv1/WithoutBiases" type="Convolution" version="opset1">
			<data strides="1, 1" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" auto_pad="explicit" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>5</dim>
					<dim>256</dim>
					<dim>2</dim>
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="99" name="emotion5_conv1/Dims1316_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 5, 1, 1" offset="4965004" size="10" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="100" name="emotion5_conv1/Dims1316" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="101" name="emotion5_conv1" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="emotion5_conv">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="102" name="prob_emotion" type="SoftMax" version="opset8">
			<data axis="1" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="prob_emotion">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="103" name="prob_emotion/sink_port_0" type="Result" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>5</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
		</layer>
	</layers>
	<edges>
		<edge from-layer="0" from-port="0" to-layer="3" to-port="0" />
		<edge from-layer="1" from-port="0" to-layer="2" to-port="0" />
		<edge from-layer="2" from-port="1" to-layer="3" to-port="1" />
		<edge from-layer="3" from-port="2" to-layer="6" to-port="0" />
		<edge from-layer="4" from-port="0" to-layer="5" to-port="0" />
		<edge from-layer="5" from-port="1" to-layer="6" to-port="1" />
		<edge from-layer="6" from-port="2" to-layer="9" to-port="0" />
		<edge from-layer="7" from-port="0" to-layer="8" to-port="0" />
		<edge from-layer="8" from-port="1" to-layer="9" to-port="1" />
		<edge from-layer="9" from-port="2" to-layer="12" to-port="0" />
		<edge from-layer="10" from-port="0" to-layer="11" to-port="0" />
		<edge from-layer="11" from-port="1" to-layer="12" to-port="1" />
		<edge from-layer="12" from-port="2" to-layer="13" to-port="0" />
		<edge from-layer="13" from-port="1" to-layer="14" to-port="0" />
		<edge from-layer="14" from-port="1" to-layer="17" to-port="0" />
		<edge from-layer="14" from-port="1" to-layer="25" to-port="1" />
		<edge from-layer="15" from-port="0" to-layer="16" to-port="0" />
		<edge from-layer="16" from-port="1" to-layer="17" to-port="1" />
		<edge from-layer="17" from-port="2" to-layer="20" to-port="0" />
		<edge from-layer="18" from-port="0" to-layer="19" to-port="0" />
		<edge from-layer="19" from-port="1" to-layer="20" to-port="1" />
		<edge from-layer="20" from-port="2" to-layer="21" to-port="0" />
		<edge from-layer="21" from-port="1" to-layer="24" to-port="0" />
		<edge from-layer="22" from-port="0" to-layer="23" to-port="0" />
		<edge from-layer="23" from-port="1" to-layer="24" to-port="1" />
		<edge from-layer="24" from-port="2" to-layer="25" to-port="0" />
		<edge from-layer="25" from-port="2" to-layer="28" to-port="0" />
		<edge from-layer="26" from-port="0" to-layer="27" to-port="0" />
		<edge from-layer="27" from-port="1" to-layer="28" to-port="1" />
		<edge from-layer="28" from-port="2" to-layer="31" to-port="0" />
		<edge from-layer="29" from-port="0" to-layer="30" to-port="0" />
		<edge from-layer="30" from-port="1" to-layer="31" to-port="1" />
		<edge from-layer="31" from-port="2" to-layer="32" to-port="0" />
		<edge from-layer="32" from-port="1" to-layer="35" to-port="0" />
		<edge from-layer="32" from-port="1" to-layer="45" to-port="0" />
		<edge from-layer="33" from-port="0" to-layer="34" to-port="0" />
		<edge from-layer="34" from-port="1" to-layer="35" to-port="1" />
		<edge from-layer="35" from-port="2" to-layer="38" to-port="0" />
		<edge from-layer="36" from-port="0" to-layer="37" to-port="0" />
		<edge from-layer="37" from-port="1" to-layer="38" to-port="1" />
		<edge from-layer="38" from-port="2" to-layer="39" to-port="0" />
		<edge from-layer="39" from-port="1" to-layer="42" to-port="0" />
		<edge from-layer="40" from-port="0" to-layer="41" to-port="0" />
		<edge from-layer="41" from-port="1" to-layer="42" to-port="1" />
		<edge from-layer="42" from-port="2" to-layer="46" to-port="0" />
		<edge from-layer="43" from-port="0" to-layer="44" to-port="0" />
		<edge from-layer="44" from-port="1" to-layer="45" to-port="1" />
		<edge from-layer="45" from-port="2" to-layer="46" to-port="1" />
		<edge from-layer="46" from-port="2" to-layer="49" to-port="0" />
		<edge from-layer="47" from-port="0" to-layer="48" to-port="0" />
		<edge from-layer="48" from-port="1" to-layer="49" to-port="1" />
		<edge from-layer="49" from-port="2" to-layer="52" to-port="0" />
		<edge from-layer="50" from-port="0" to-layer="51" to-port="0" />
		<edge from-layer="51" from-port="1" to-layer="52" to-port="1" />
		<edge from-layer="52" from-port="2" to-layer="53" to-port="0" />
		<edge from-layer="53" from-port="1" to-layer="56" to-port="0" />
		<edge from-layer="53" from-port="1" to-layer="66" to-port="0" />
		<edge from-layer="54" from-port="0" to-layer="55" to-port="0" />
		<edge from-layer="55" from-port="1" to-layer="56" to-port="1" />
		<edge from-layer="56" from-port="2" to-layer="59" to-port="0" />
		<edge from-layer="57" from-port="0" to-layer="58" to-port="0" />
		<edge from-layer="58" from-port="1" to-layer="59" to-port="1" />
		<edge from-layer="59" from-port="2" to-layer="60" to-port="0" />
		<edge from-layer="60" from-port="1" to-layer="63" to-port="0" />
		<edge from-layer="61" from-port="0" to-layer="62" to-port="0" />
		<edge from-layer="62" from-port="1" to-layer="63" to-port="1" />
		<edge from-layer="63" from-port="2" to-layer="67" to-port="0" />
		<edge from-layer="64" from-port="0" to-layer="65" to-port="0" />
		<edge from-layer="65" from-port="1" to-layer="66" to-port="1" />
		<edge from-layer="66" from-port="2" to-layer="67" to-port="1" />
		<edge from-layer="67" from-port="2" to-layer="70" to-port="0" />
		<edge from-layer="68" from-port="0" to-layer="69" to-port="0" />
		<edge from-layer="69" from-port="1" to-layer="70" to-port="1" />
		<edge from-layer="70" from-port="2" to-layer="73" to-port="0" />
		<edge from-layer="71" from-port="0" to-layer="72" to-port="0" />
		<edge from-layer="72" from-port="1" to-layer="73" to-port="1" />
		<edge from-layer="73" from-port="2" to-layer="74" to-port="0" />
		<edge from-layer="74" from-port="1" to-layer="77" to-port="0" />
		<edge from-layer="74" from-port="1" to-layer="87" to-port="0" />
		<edge from-layer="75" from-port="0" to-layer="76" to-port="0" />
		<edge from-layer="76" from-port="1" to-layer="77" to-port="1" />
		<edge from-layer="77" from-port="2" to-layer="80" to-port="0" />
		<edge from-layer="78" from-port="0" to-layer="79" to-port="0" />
		<edge from-layer="79" from-port="1" to-layer="80" to-port="1" />
		<edge from-layer="80" from-port="2" to-layer="81" to-port="0" />
		<edge from-layer="81" from-port="1" to-layer="84" to-port="0" />
		<edge from-layer="82" from-port="0" to-layer="83" to-port="0" />
		<edge from-layer="83" from-port="1" to-layer="84" to-port="1" />
		<edge from-layer="84" from-port="2" to-layer="88" to-port="0" />
		<edge from-layer="85" from-port="0" to-layer="86" to-port="0" />
		<edge from-layer="86" from-port="1" to-layer="87" to-port="1" />
		<edge from-layer="87" from-port="2" to-layer="88" to-port="1" />
		<edge from-layer="88" from-port="2" to-layer="91" to-port="0" />
		<edge from-layer="89" from-port="0" to-layer="90" to-port="0" />
		<edge from-layer="90" from-port="1" to-layer="91" to-port="1" />
		<edge from-layer="91" from-port="2" to-layer="94" to-port="0" />
		<edge from-layer="92" from-port="0" to-layer="93" to-port="0" />
		<edge from-layer="93" from-port="1" to-layer="94" to-port="1" />
		<edge from-layer="94" from-port="2" to-layer="95" to-port="0" />
		<edge from-layer="95" from-port="1" to-layer="98" to-port="0" />
		<edge from-layer="96" from-port="0" to-layer="97" to-port="0" />
		<edge from-layer="97" from-port="1" to-layer="98" to-port="1" />
		<edge from-layer="98" from-port="2" to-layer="101" to-port="0" />
		<edge from-layer="99" from-port="0" to-layer="100" to-port="0" />
		<edge from-layer="100" from-port="1" to-layer="101" to-port="1" />
		<edge from-layer="101" from-port="2" to-layer="102" to-port="0" />
		<edge from-layer="102" from-port="1" to-layer="103" to-port="0" />
	</edges>
	<rt_info>
		<MO_version value="custom_HEAD_3b86f12c37fa7b35388be509ccabf6c7423268b7" />
		<Runtime_version value="2022.3.0-8987-3b86f12c37f-HEAD" />
		<conversion_parameters>
			<caffe_parser_path value="DIR" />
			<data_type value="FP16" />
			<framework value="caffe" />
			<input value="data" />
			<input_model value="DIR/0003_EmoNet_ResNet10.caffemodel" />
			<input_proto value="DIR/0003_EmoNet_ResNet10.prototxt" />
			<input_shape value="[1,3,64,64]" />
			<layout value="data(nchw)" />
			<model_name value="emotions-recognition-retail-0003" />
			<output value="prob_emotion" />
			<output_dir value="DIR" />
			<scale_values value="data[1.0]" />
		</conversion_parameters>
		<legacy_frontend value="True" />
	</rt_info>
</net>
